{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6dcb6f1",
   "metadata": {},
   "source": [
    "FITTING MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "958b004e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, VotingRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "fe6be4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('clean_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "09090aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(y_hat, y):\n",
    "#     print(\"Mean absolute error: %.2f\" % np.mean(np.absolute(y_hat - y)))\n",
    "#     print(\"Residual sum of squares (MSE): %.2f\" % np.mean((y_hat - y) ** 2))\n",
    "#     print( f'Normalized sum of squares error: {round(100*np.mean((y_hat - y) ** 2) / (np.mean(y ** 2)), 2)}%' )\n",
    "#     print(\"R2-score: %.2f\" % r2_score(y_hat, y) )\n",
    "    return [round(np.mean(np.absolute(y_hat - y)), 2), round(np.mean((y_hat - y) ** 2),2), \n",
    "            round(np.mean((y_hat - y) ** 2) / (np.mean(y ** 2)),2), \n",
    "            round(r2_score(y_hat, y),2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "4934eeee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================\n",
      "Simple linear regression\n",
      "=====================\n",
      "Coefficients in simple linear regression:  [107.46]\n",
      "Intercept in simple linear regression:  18087.3\n",
      "Variance score: 0.58\n",
      "=====================\n",
      "Multi-linear regression with all features\n",
      "=====================\n",
      "20 largest coefficients in multilinear regression: [136739.7, 126478.74, 88428.24, 84537.37, 79812.68, 62871.15, 46533.43, 41912.18, 34245.47, 28744.96, 27812.74, 24488.27, 23894.09, 22112.31, 21980.77, 19469.72, 18532.28, 18341.69, 17599.76, 17369.59]\n",
      "Intercept in multilinear regression: -1799839.24\n",
      "Variance score: 0.85\n",
      "=====================\n",
      "Multi-linear regression using 3 features most correlated with the SalePrice\n",
      "=====================\n",
      "Coefficients in multilinear regression:[54.56, 23793.37, 32575.56]\n",
      "Intercept in multilinear regression:  -157333.64\n"
     ]
    }
   ],
   "source": [
    "#Train-test split\n",
    "msk = np.random.rand(len(df)) < 0.8\n",
    "train = df[msk]\n",
    "test = df[~msk]\n",
    "\n",
    "metrics = {}\n",
    "\n",
    "#MODEL 1: Simple linear regression\n",
    "print('=====================')\n",
    "print('Simple linear regression')\n",
    "print('=====================')\n",
    "\n",
    "#a) Data preparation\n",
    "X_train = train['GrLivArea'].values.reshape(-1,1)\n",
    "y_train = train['SalePrice']\n",
    "X_test = test['GrLivArea'].values.reshape(-1,1)\n",
    "y_test = test['SalePrice']\n",
    "\n",
    "#b) Fitting the model\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X_train, y_train)\n",
    "print ('Coefficients in simple linear regression: ', [round(num,2) for num in regr.coef_])\n",
    "print ('Intercept in simple linear regression: ', round(regr.intercept_,2))\n",
    "\n",
    "#c) Drawing a graph\n",
    "# plt.scatter(train.GrLivArea, train.SalePrice,  color='blue')\n",
    "# plt.plot(train.GrLivArea, regr.coef_*train.GrLivArea + regr.intercept_, '-r')\n",
    "# plt.title('GrLivArea vs SalePrice')\n",
    "# plt.xlabel(\"GrLivArea\")\n",
    "# plt.ylabel(\"SalePrice\")\n",
    "\n",
    "#d) Prediction and evaluation\n",
    "y_test_hat = regr.predict(X_test)\n",
    "metrics['SLR'] = eval(y_test_hat, y_test )\n",
    "print('Variance score: %.2f' % regr.score(X_test, y_test))\n",
    "\n",
    "#MODEL 2: Multi-linear regression with all features\n",
    "print('=====================')\n",
    "print('Multi-linear regression with all features')\n",
    "print('=====================')\n",
    "#a) Data preparation\n",
    "X_train = train.drop(columns = ['SalePrice'])\n",
    "y_train = train['SalePrice']\n",
    "X_test = test.drop(columns = ['SalePrice'])\n",
    "y_test = test['SalePrice']\n",
    "\n",
    "#b) Fitting the model\n",
    "ml_regr = linear_model.LinearRegression()\n",
    "ml_regr.fit(X_train, y_train)\n",
    "print (f'20 largest coefficients in multilinear regression: {[round(num, 2) for num in sorted(ml_regr.coef_, reverse=True)[:20]]}')\n",
    "print ('Intercept in multilinear regression: %.2f' % round(ml_regr.intercept_,2))\n",
    "\n",
    "#c) Drawing a graph - not clear how to do it in this case.\n",
    "\n",
    "#d) Prediction and evaluation\n",
    "y_test_hat = ml_regr.predict(X_test)\n",
    "metrics['MLR'] = eval(y_test_hat, y_test)\n",
    "print('Variance score: %.2f' % ml_regr.score(X_test, y_test))\n",
    "\n",
    "#MODEL 3: Multi-linear regression using 3 features most correlated with the SalePrice\n",
    "print('=====================')\n",
    "print('Multi-linear regression using 3 features most correlated with the SalePrice')\n",
    "print('=====================')\n",
    "#a) Data preparation\n",
    "X_train = train[['GrLivArea','OverallQual', 'ExterQual']]\n",
    "y_train = train['SalePrice']\n",
    "X_test = test[['GrLivArea','OverallQual', 'ExterQual']]\n",
    "y_test = test['SalePrice']\n",
    "\n",
    "#b) Fitting the model\n",
    "ml3_regr = linear_model.LinearRegression()\n",
    "ml3_regr.fit(X_train, y_train)\n",
    "print (f'Coefficients in multilinear regression:{[round(num, 2) for num in ml3_regr.coef_]}')\n",
    "print ('Intercept in multilinear regression: ', round(ml3_regr.intercept_,2))\n",
    "\n",
    "#c) Drawing a graph - not clear how to do it in this case.\n",
    "\n",
    "#d) Prediction and evaluation\n",
    "y_test_hat = ml3_regr.predict(X_test)\n",
    "metrics['MLR3'] = eval(y_test_hat, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "3b5f4391",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL 4: k nearest neighbors regression\n",
    "\n",
    "#a) Data preparation \n",
    "X_train = train.drop(columns = ['SalePrice'])\n",
    "y_train = train['SalePrice']\n",
    "X_test = test.drop(columns = ['SalePrice'])\n",
    "y_test = test['SalePrice']\n",
    "\n",
    "#d) Prediction and evaluation\n",
    "for x in range(1, 10):\n",
    "    y_test_hat = KNeighborsRegressor(x).fit(X_train,y_train).predict(X_test)\n",
    "#     print('=====================')\n",
    "#     print(f'KNN regression with k = {x}')\n",
    "#     print('=====================')\n",
    "    metrics[f'KNN_{x}']= eval(y_test_hat, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "4282caee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL 5: SVM regression\n",
    "\n",
    "#a) Data preparation \n",
    "X_train = train.drop(columns = ['SalePrice'])\n",
    "y_train = train['SalePrice']\n",
    "X_test = test.drop(columns = ['SalePrice'])\n",
    "y_test = test['SalePrice']\n",
    "\n",
    "#d) Prediction and evaluation\n",
    "for x in range(1,5):\n",
    "    y_test_hat = LinearSVR(C=1, epsilon=25000*x, max_iter=100000).fit(X_train,y_train).predict(X_test)\n",
    "#     print('=====================')\n",
    "#     print(f'Support vector regression with epsilon = {25000*x}')\n",
    "#     print('=====================')\n",
    "    metrics[f'SVM_epsilon={25000*x}'] = eval(y_test_hat, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6b0a6b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL 6, 7: Decision tree and Random forest\n",
    "\n",
    "#a) Data preparation \n",
    "X_train = train.drop(columns = ['SalePrice'])\n",
    "y_train = train['SalePrice']\n",
    "X_test = test.drop(columns = ['SalePrice'])\n",
    "y_test = test['SalePrice']\n",
    "\n",
    "#d) Prediction and evaluation\n",
    "for x in range(1,10):\n",
    "    y_test_hat = DecisionTreeRegressor(max_depth = x).fit(X_train,y_train).predict(X_test)\n",
    "    metrics[f'Decision_tree_max_depth={x}'] = eval(y_test_hat, y_test)\n",
    "    \n",
    "    y_test_hat = RandomForestRegressor(max_depth = x).fit(X_train,y_train).predict(X_test)\n",
    "    metrics[f'Random_forest_max_depth={x}'] = eval(y_test_hat, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d68e1fc",
   "metadata": {},
   "source": [
    "Below we will study several regularized regression model. Their common feature is that they all penalize large regression coefficients. In case of Ridge regression it is achieved by adding $\\alpha\\|\\theta\\|^2_{\\ell^2}$ to the MSE. In LASSO regression one adds $\\alpha\\|\\theta\\|_{\\ell^1}$ instead. Finally, in the Elastic Net approach we add a convex combination:\n",
    "$\\alpha\\Big[r\\|\\theta\\|^2_{\\ell^2}+(1-r)\\|\\theta\\|_{\\ell^1}\\Big]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "4e4f1037",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL 8,9 and 10: Regularized regression models\n",
    "\n",
    "#a) Data preparation \n",
    "X_train = train.drop(columns = ['SalePrice'])\n",
    "y_train = train['SalePrice']\n",
    "X_test = test.drop(columns = ['SalePrice'])\n",
    "y_test = test['SalePrice']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_rescaled = scaler.transform(X_train)\n",
    "X_test_rescaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "023b7e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#d) Prediction and evaluation\n",
    "\n",
    "for x in range(1,10):\n",
    "\n",
    "#With rescaling\n",
    "\n",
    "    y_test_hat = Ridge(alpha= x/10).fit(X_train_rescaled, y_train).predict(X_test_rescaled)\n",
    "    metrics[f'Ridge rescaled with alpha={x/10}'] = eval(y_test_hat, y_test)\n",
    "    \n",
    "    y_test_hat = Lasso(alpha= x/10).fit(X_train_rescaled, y_train).predict(X_test_rescaled)\n",
    "    metrics[f'Lasso rescaled with alpha={x/10}'] = eval(y_test_hat, y_test)\n",
    "\n",
    "#Without rescaling:\n",
    "    \n",
    "    y_test_hat = Ridge(alpha= x/10).fit(X_train, y_train).predict(X_test)\n",
    "    metrics[f'Ridge not rescaled with alpha={x/10}'] = eval(y_test_hat, y_test)\n",
    "\n",
    "    y_test_hat = Lasso(alpha= x/10).fit(X_train, y_train).predict(X_test)\n",
    "    metrics[f'Lasso not rescaled with alpha={x/10}'] = eval(y_test_hat, y_test)\n",
    "\n",
    "    \n",
    "    for r in range(1,10):\n",
    "        \n",
    "            y_test_hat = ElasticNet(alpha= x/10, l1_ratio = r/10).fit(X_train, y_train).predict(X_test)\n",
    "            metrics[f'ElasticNet not rescaled with alpha={x/10} and r={r/10}'] = eval(y_test_hat, y_test)\n",
    "            \n",
    "            y_test_hat = ElasticNet(alpha= x/10, l1_ratio = r/10).fit(X_train_rescaled, y_train).predict(X_test_rescaled)\n",
    "            metrics[f'ElasticNet rescaled with alpha={x/10} and r={r/10}'] = eval(y_test_hat, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "665c1a97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>relative MSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Random_forest_max_depth=9</th>\n",
       "      <td>16620.82</td>\n",
       "      <td>710063043.80</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNet rescaled with alpha=0.9 and r=0.9</th>\n",
       "      <td>18099.42</td>\n",
       "      <td>857423207.74</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso not rescaled with alpha=0.2</th>\n",
       "      <td>19636.62</td>\n",
       "      <td>903936775.33</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge not rescaled with alpha=0.3</th>\n",
       "      <td>18584.27</td>\n",
       "      <td>862706359.45</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso rescaled with alpha=0.3</th>\n",
       "      <td>19465.12</td>\n",
       "      <td>879953091.29</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  MAE          MSE  \\\n",
       "Random_forest_max_depth=9                    16620.82 710063043.80   \n",
       "ElasticNet rescaled with alpha=0.9 and r=0.9 18099.42 857423207.74   \n",
       "Lasso not rescaled with alpha=0.2            19636.62 903936775.33   \n",
       "Ridge not rescaled with alpha=0.3            18584.27 862706359.45   \n",
       "Lasso rescaled with alpha=0.3                19465.12 879953091.29   \n",
       "\n",
       "                                              relative MSE   R2  \n",
       "Random_forest_max_depth=9                             0.02 0.85  \n",
       "ElasticNet rescaled with alpha=0.9 and r=0.9          0.02 0.84  \n",
       "Lasso not rescaled with alpha=0.2                     0.02 0.84  \n",
       "Ridge not rescaled with alpha=0.3                     0.02 0.84  \n",
       "Lasso rescaled with alpha=0.3                         0.02 0.84  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "df = pd.DataFrame.from_dict(metrics, orient='index', dtype=float, columns= ['MAE', 'MSE','relative MSE', 'R2'])\n",
    "sorted_df = df.sort_values(by = ['R2'], ascending = False)\n",
    "sorted_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a5c9a6",
   "metadata": {},
   "source": [
    "Now we will build a voting regressor based on the 5 top performing models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "9dbf0f3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[16071.47, 741924185.74, 0.02, 0.85]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfr9 = RandomForestRegressor(max_depth = 9)\n",
    "elnet = ElasticNet(alpha= 0.9, l1_ratio = 0.9)\n",
    "lasso = Lasso(alpha= 0.2)\n",
    "ridge = Lasso(alpha= 0.3)\n",
    "\n",
    "voting_reg = VotingRegressor(estimators = [('rfr', rfr9),('en',elnet),('lass', lasso), ('ridg', ridge)])\n",
    "voting_reg.fit(X_train, y_train)\n",
    "y_test_hat = voting_reg.predict(X_test)\n",
    "metrics[f'VotingRegressor'] = eval(y_test_hat, y_test)\n",
    "metrics[f'VotingRegressor']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abfa481",
   "metadata": {},
   "source": [
    "So Voting Regressor performs better than the best model! Next we will try some boosting methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "d3e59ddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15603.6, 602160155.38, 0.02, 0.88]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_boost = AdaBoostRegressor( DecisionTreeRegressor(max_depth = 10), n_estimators = 400, learning_rate = 0.5 )\n",
    "y_test_hat = ada_boost.fit(X_train, y_train).predict(X_test)\n",
    "metrics[f'AdaBoostRegressor'] = eval(y_test_hat, y_test)\n",
    "metrics[f'AdaBoostRegressor']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8687ad79",
   "metadata": {},
   "source": [
    "The choice of parameters: max_depth = 10, n_estimators = 400, learning_rate = 0.5 is somehow arbitrary. I tried \n",
    "plugging different values here; in general the larger max_depth and n_estimators, the more accurate the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "09e8f980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[18344.57, 712825326.74, 0.02, 0.86]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_boost = GradientBoostingRegressor( max_depth = 10, n_estimators = 400, learning_rate = 0.4 )\n",
    "y_test_hat = gradient_boost.fit(X_train, y_train).predict(X_test)\n",
    "metrics[f'GradientBoostingRegressor'] = eval(y_test_hat, y_test)\n",
    "metrics[f'GradientBoostingRegressor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "aa54248b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>relative MSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <td>15603.60</td>\n",
       "      <td>602160155.38</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <td>18344.57</td>\n",
       "      <td>712825326.74</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VotingRegressor</th>\n",
       "      <td>16071.47</td>\n",
       "      <td>741924185.74</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random_forest_max_depth=9</th>\n",
       "      <td>16620.82</td>\n",
       "      <td>710063043.80</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge rescaled with alpha=0.5</th>\n",
       "      <td>19631.16</td>\n",
       "      <td>905540160.35</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNet rescaled with alpha=0.1 and r=0.9</th>\n",
       "      <td>19289.38</td>\n",
       "      <td>893389364.57</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNet rescaled with alpha=0.1 and r=0.8</th>\n",
       "      <td>19043.93</td>\n",
       "      <td>883811675.69</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNet rescaled with alpha=0.4 and r=0.8</th>\n",
       "      <td>18192.36</td>\n",
       "      <td>859004171.61</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNet rescaled with alpha=0.1 and r=0.7</th>\n",
       "      <td>18852.69</td>\n",
       "      <td>876721787.56</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNet rescaled with alpha=0.4 and r=0.9</th>\n",
       "      <td>18688.72</td>\n",
       "      <td>871324407.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  MAE          MSE  \\\n",
       "AdaBoostRegressor                            15603.60 602160155.38   \n",
       "GradientBoostingRegressor                    18344.57 712825326.74   \n",
       "VotingRegressor                              16071.47 741924185.74   \n",
       "Random_forest_max_depth=9                    16620.82 710063043.80   \n",
       "Ridge rescaled with alpha=0.5                19631.16 905540160.35   \n",
       "ElasticNet rescaled with alpha=0.1 and r=0.9 19289.38 893389364.57   \n",
       "ElasticNet rescaled with alpha=0.1 and r=0.8 19043.93 883811675.69   \n",
       "ElasticNet rescaled with alpha=0.4 and r=0.8 18192.36 859004171.61   \n",
       "ElasticNet rescaled with alpha=0.1 and r=0.7 18852.69 876721787.56   \n",
       "ElasticNet rescaled with alpha=0.4 and r=0.9 18688.72 871324407.04   \n",
       "\n",
       "                                              relative MSE   R2  \n",
       "AdaBoostRegressor                                     0.02 0.88  \n",
       "GradientBoostingRegressor                             0.02 0.86  \n",
       "VotingRegressor                                       0.02 0.85  \n",
       "Random_forest_max_depth=9                             0.02 0.85  \n",
       "Ridge rescaled with alpha=0.5                         0.02 0.84  \n",
       "ElasticNet rescaled with alpha=0.1 and r=0.9          0.02 0.84  \n",
       "ElasticNet rescaled with alpha=0.1 and r=0.8          0.02 0.84  \n",
       "ElasticNet rescaled with alpha=0.4 and r=0.8          0.02 0.84  \n",
       "ElasticNet rescaled with alpha=0.1 and r=0.7          0.02 0.84  \n",
       "ElasticNet rescaled with alpha=0.4 and r=0.9          0.02 0.84  "
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(metrics, orient='index', dtype=float, columns= ['MAE', 'MSE','relative MSE', 'R2'])\n",
    "sorted_df = df.sort_values(by = ['R2'], ascending = False)\n",
    "sorted_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352ecc73",
   "metadata": {},
   "source": [
    "We see that the ensemble/boosting techniques improve our models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
