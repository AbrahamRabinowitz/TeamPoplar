{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e91a2a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "# We start off with the baseline import statements we need to do the basic data manipulation and visualization.\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import calendar\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "#We create and set aside a copy of the data for initial exploration\n",
    "housing_train = pd.read_csv('../data/train.csv')\n",
    "housing = housing_train.copy()\n",
    "\n",
    "#MISSING DATA\n",
    "total = housing.isnull().sum().sort_values(ascending=False)\n",
    "percent = (housing.isnull().sum()/housing.isnull().count()).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "\n",
    "#CORRELATION CHECK\n",
    "corr_matrix = housing.corr()\n",
    "top_corr = corr_matrix['SalePrice'].sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b01a5e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DROPPING SOME COLUMNS\n",
    "drop = ['PoolQC', 'PoolArea','MiscFeature', 'MiscVal', 'Alley', 'Fence', 'FireplaceQu', 'Fireplaces', 'LotFrontage']\n",
    "drop2 = ['Id','GarageArea','1stFlrSF','GarageYrBlt']\n",
    "housing.drop(columns = drop + drop2, inplace = True)\n",
    "housing['Age'] = housing['YrSold'] - housing['YearBuilt']\n",
    "housing['AgeRemodel'] = housing['YrSold'] - housing['YearRemodAdd']\n",
    "housing = housing[housing.AgeRemodel >= 0]\n",
    "housing.drop(columns = ['YearBuilt','YearRemodAdd'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6f1b8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\barto\\AppData\\Local\\Temp\\ipykernel_9860\\949234473.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  housing_numeric_one_hot['MSSubClass'] = housing_numeric_one_hot['MSSubClass'].astype('str')\n",
      "C:\\Users\\barto\\AppData\\Local\\Temp\\ipykernel_9860\\949234473.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  housing_numeric_one_hot['MoSold'] = housing_numeric_one_hot['MoSold'].replace({i:calendar.month_name[i][:3] for i in range(1,13)})\n",
      "C:\\Users\\barto\\AppData\\Local\\Temp\\ipykernel_9860\\949234473.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  housing_cat_ordinal.fillna('None', inplace = True)\n",
      "C:\\Users\\barto\\AppData\\Local\\Temp\\ipykernel_9860\\949234473.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  housing_cat_ordinal[cat].replace(mapper(cat), inplace = True)\n"
     ]
    }
   ],
   "source": [
    "#FURTHER DATA CLEANING\n",
    "housing_cat = housing.select_dtypes(exclude=[np.number])\n",
    "housing_numeric = housing.select_dtypes(include=[np.number])\n",
    "\n",
    "#Numeric\n",
    "numeric_unbounded = ['LotArea', 'MasVnrArea','BsmtFinSF1','BsmtFinSF2', 'BsmtUnfSF',\n",
    "                     'TotalBsmtSF','2ndFlrSF','LowQualFinSF','GrLivArea','WoodDeckSF',\n",
    "                     'OpenPorchSF','EnclosedPorch','3SsnPorch','ScreenPorch', 'SalePrice',\n",
    "                     'Age','AgeRemodel']\n",
    "\n",
    "numeric_one_hot = ['MSSubClass','MoSold']\n",
    "\n",
    "numeric_ordinal = [x for x in housing_numeric.columns \n",
    "                   if (x not in numeric_unbounded and x not in numeric_one_hot)]\n",
    "\n",
    "housing_numeric_unbounded = housing_numeric[numeric_unbounded]\n",
    "housing_numeric_one_hot = housing_numeric[numeric_one_hot]\n",
    "housing_numeric_ordinal = housing_numeric[numeric_ordinal]\n",
    "\n",
    "housing_numeric_one_hot['MSSubClass'] = housing_numeric_one_hot['MSSubClass'].astype('str')\n",
    "housing_numeric_one_hot['MoSold'] = housing_numeric_one_hot['MoSold'].replace({i:calendar.month_name[i][:3] for i in range(1,13)})\n",
    "housing_numeric_one_hot = pd.get_dummies(housing_numeric_one_hot)\n",
    "\n",
    "#Categorical\n",
    "cat_ordinal = ['ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'BsmtExposure',\n",
    "               'BsmtFinType1', 'HeatingQC', 'KitchenQual','Functional','GarageFinish',\n",
    "               'GarageQual', 'GarageCond']\n",
    "\n",
    "housing_cat_ordinal = housing_cat[cat_ordinal]\n",
    "housing_cat_ordinal.fillna('None', inplace = True)\n",
    "housing_cat_one_hot = housing_cat.drop(columns = cat_ordinal)\n",
    "housing_cat_one_hot = pd.get_dummies(housing_cat_one_hot)\n",
    "\n",
    "def mapper(cat):\n",
    "    if cat in ['ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'GarageQual', 'GarageCond',\n",
    "               'HeatingQC', 'KitchenQual']:\n",
    "        mapper = {'None':0, 'Po':1, 'Fa':2,'TA':3,'Gd':4,'Ex':5}\n",
    "    elif cat == 'BsmtExposure':\n",
    "            mapper = {'None':0,'No':1, 'Mn':2, 'Av':3,'Gd':4}\n",
    "    elif cat == 'BsmtFinType1':\n",
    "        mapper = {'None':0,'Unf':1,'LwQ':2,'Rec':3,'BLQ':4,'ALQ':5,'GLQ':6}\n",
    "    elif cat == 'Functional':\n",
    "        mapper = {'Sal':0,'Sev':1,'Maj2':2,'Maj1':3,'Mod':4,'Min2':5, 'Min1':6,'Typ':7}\n",
    "    else:\n",
    "        mapper = {'None':0,'Unf':1,'RFn':2,'Fin':3}\n",
    "        \n",
    "    return mapper\n",
    "\n",
    "for cat in cat_ordinal:\n",
    "    housing_cat_ordinal[cat].replace(mapper(cat), inplace = True)\n",
    "\n",
    "#Combining numeric and categorical\n",
    "housing_ordinal = pd.concat([housing_numeric_ordinal,housing_cat_ordinal], axis = 'columns')\n",
    "housing_one_hot = pd.concat([housing_numeric_one_hot, housing_cat_one_hot], axis = 'columns')\n",
    "housing_clean = pd.concat([housing_one_hot, housing_ordinal, housing_numeric_unbounded], \n",
    "                          axis = 'columns')\n",
    "\n",
    "#MORE CORRELATION\n",
    "ordinal_prices = pd.concat([housing_ordinal, housing['SalePrice']], axis = 'columns')\n",
    "ordinal_corr_matrix = ordinal_prices.corr()\n",
    "top_corr_ordinal = ordinal_corr_matrix['SalePrice'].sort_values(ascending = False)\n",
    "\n",
    "one_hot_prices = pd.concat([housing_one_hot, housing['SalePrice']], axis = 'columns')\n",
    "one_hot_corr_matrix = one_hot_prices.corr()\n",
    "top_corr_one_hot = one_hot_corr_matrix['SalePrice'].filter(like = 'Neighborhood').sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5d3650d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#REMOVAL OF THE REMAINING NaN\n",
    "housing_clean.isnull().sum().sort_values(ascending=False)\n",
    "df = housing_clean.copy()\n",
    "problem_col = df.isin([np.nan, np.inf, -np.inf]).sum(axis=0)[df.isin([np.nan, np.inf, -np.inf]).sum(axis=0) != 0] \n",
    "index_to_drop = df[problem_col.index[0]][df[problem_col.index[0]].isin([np.nan, np.inf, -np.inf])].index\n",
    "df.drop(index = index_to_drop, inplace = True)\n",
    "# df.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f08a6b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RANDOM FOREST FOR FEATURE IMPORTANCE\n",
    "X_train = df.drop(columns = ['SalePrice'])\n",
    "y_train = df['SalePrice']\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=500, max_depth=4)\n",
    "\n",
    "forest.fit(X_train, y_train)\n",
    "\n",
    "forest.feature_importances_\n",
    "score_df = pd.DataFrame({'feature':X_train.columns,\n",
    "                            'importance_score': forest.feature_importances_})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe8461b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will look at feature importances and their correlation with the 'SalePrice'\n",
    "score_df.sort_values('feature', inplace=True)\n",
    "top_corr = df.corr()['SalePrice'].abs().drop(index = ['SalePrice']) #I suppose we want to look at the absolute value\n",
    "                                                                    #of the correlation. Is that right?\n",
    "top_corr.sort_index(inplace=True) \n",
    "#now rows of score_df and top_corr match and we can add the values of correlation\n",
    "score_df['correlation'] = top_corr.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "17ede219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance_score</th>\n",
       "      <th>correlation</th>\n",
       "      <th>importance_score_rank</th>\n",
       "      <th>correlation_rank</th>\n",
       "      <th>overall_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OverallQual</td>\n",
       "      <td>0.026840</td>\n",
       "      <td>0.792084</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GrLivArea</td>\n",
       "      <td>0.032454</td>\n",
       "      <td>0.718891</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ExterQual</td>\n",
       "      <td>0.012564</td>\n",
       "      <td>0.682920</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>11.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KitchenQual</td>\n",
       "      <td>0.013004</td>\n",
       "      <td>0.659501</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>11.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GarageCars</td>\n",
       "      <td>0.016247</td>\n",
       "      <td>0.640228</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TotalBsmtSF</td>\n",
       "      <td>0.024386</td>\n",
       "      <td>0.617630</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BsmtQual</td>\n",
       "      <td>0.013732</td>\n",
       "      <td>0.584715</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>FullBath</td>\n",
       "      <td>0.020979</td>\n",
       "      <td>0.563726</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GarageFinish</td>\n",
       "      <td>0.009187</td>\n",
       "      <td>0.549291</td>\n",
       "      <td>27</td>\n",
       "      <td>9</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TotRmsAbvGrd</td>\n",
       "      <td>0.019372</td>\n",
       "      <td>0.537623</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Age</td>\n",
       "      <td>0.027841</td>\n",
       "      <td>0.523432</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AgeRemodel</td>\n",
       "      <td>0.020766</td>\n",
       "      <td>0.509143</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>10.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Foundation_PConc</td>\n",
       "      <td>0.006281</td>\n",
       "      <td>0.497654</td>\n",
       "      <td>33</td>\n",
       "      <td>13</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MasVnrArea</td>\n",
       "      <td>0.014569</td>\n",
       "      <td>0.479554</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>14.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>HeatingQC</td>\n",
       "      <td>0.007930</td>\n",
       "      <td>0.427698</td>\n",
       "      <td>31</td>\n",
       "      <td>15</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Neighborhood_NridgHt</td>\n",
       "      <td>0.002447</td>\n",
       "      <td>0.396459</td>\n",
       "      <td>108</td>\n",
       "      <td>16</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>BsmtFinSF1</td>\n",
       "      <td>0.016859</td>\n",
       "      <td>0.385961</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>14.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>MSSubClass_60</td>\n",
       "      <td>0.003687</td>\n",
       "      <td>0.380555</td>\n",
       "      <td>54</td>\n",
       "      <td>18</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>BsmtExposure</td>\n",
       "      <td>0.008006</td>\n",
       "      <td>0.373328</td>\n",
       "      <td>29</td>\n",
       "      <td>19</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>MasVnrType_None</td>\n",
       "      <td>0.003801</td>\n",
       "      <td>0.373217</td>\n",
       "      <td>53</td>\n",
       "      <td>20</td>\n",
       "      <td>36.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 feature  importance_score  correlation  \\\n",
       "0            OverallQual          0.026840     0.792084   \n",
       "1              GrLivArea          0.032454     0.718891   \n",
       "2              ExterQual          0.012564     0.682920   \n",
       "3            KitchenQual          0.013004     0.659501   \n",
       "4             GarageCars          0.016247     0.640228   \n",
       "5            TotalBsmtSF          0.024386     0.617630   \n",
       "6               BsmtQual          0.013732     0.584715   \n",
       "7               FullBath          0.020979     0.563726   \n",
       "8           GarageFinish          0.009187     0.549291   \n",
       "9           TotRmsAbvGrd          0.019372     0.537623   \n",
       "10                   Age          0.027841     0.523432   \n",
       "11            AgeRemodel          0.020766     0.509143   \n",
       "12      Foundation_PConc          0.006281     0.497654   \n",
       "13            MasVnrArea          0.014569     0.479554   \n",
       "14             HeatingQC          0.007930     0.427698   \n",
       "15  Neighborhood_NridgHt          0.002447     0.396459   \n",
       "16            BsmtFinSF1          0.016859     0.385961   \n",
       "17         MSSubClass_60          0.003687     0.380555   \n",
       "18          BsmtExposure          0.008006     0.373328   \n",
       "19       MasVnrType_None          0.003801     0.373217   \n",
       "\n",
       "    importance_score_rank  correlation_rank  overall_rank  \n",
       "0                       4                 1           2.5  \n",
       "1                       1                 2           1.5  \n",
       "2                      20                 3          11.5  \n",
       "3                      19                 4          11.5  \n",
       "4                      13                 5           9.0  \n",
       "5                       6                 6           6.0  \n",
       "6                      17                 7          12.0  \n",
       "7                       8                 8           8.0  \n",
       "8                      27                 9          18.0  \n",
       "9                      10                10          10.0  \n",
       "10                      3                11           7.0  \n",
       "11                      9                12          10.5  \n",
       "12                     33                13          23.0  \n",
       "13                     15                14          14.5  \n",
       "14                     31                15          23.0  \n",
       "15                    108                16          62.0  \n",
       "16                     12                17          14.5  \n",
       "17                     54                18          36.0  \n",
       "18                     29                19          24.0  \n",
       "19                     53                20          36.5  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df.sort_values(ascending=False, by = ['importance_score'], inplace = True)\n",
    "score_df['importance_score_rank'] = [k for k in range(1,1+len(score_df.index))]\n",
    "score_df.sort_values(ascending=False, by = ['correlation'], inplace = True)\n",
    "score_df['correlation_rank'] = [k for k in range(1,1+len(score_df.index))]\n",
    "score_df['overall_rank'] = (score_df['importance_score_rank'] + score_df['correlation_rank'])/2 \n",
    "# score_df.sort_values(ascending=True, by = ['overall_rank'], inplace = True)\n",
    "score_df.sort_values(ascending=True, by = ['correlation_rank'], inplace = True)\n",
    "score_df.reset_index(drop = True, inplace = True)\n",
    "score_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9e60ce",
   "metadata": {},
   "source": [
    "Correlation measures only linear dependence between variables and it does not detect non-linear dependence (in particular cor(X,Y) can be 0 for random variables X and Y=X^2, which are of course completely dependent). So, if a given feature has high feature_importance score, but low correlation it means that 'SalePrice' depend on it in a non-linear manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45386661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(7, 7))\n",
    "# plt.scatter(score_df['importance_score_rank'][:20], score_df['correlation_rank'][:20], c =\"blue\",\n",
    "#             linewidths = 1)\n",
    "# plt.title('importance_rank vs correlation_rank')\n",
    "# plt.xticks(np.arange(0, 40, step=1))\n",
    "# plt.yticks(np.arange(0, 40, step=1))\n",
    "# plt.xlabel(\"importance_score_rank\")\n",
    "# plt.ylabel(\"correlation_rank\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac088190",
   "metadata": {},
   "source": [
    "FITTING MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "e3162cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "259066de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(y_hat, y):\n",
    "    print(\"Mean absolute error: %.2f\" % np.mean(np.absolute(y_hat - y)))\n",
    "    print(\"Residual sum of squares (MSE): %.2f\" % np.mean((y_hat - y) ** 2))\n",
    "    print( f'Normalized sum of squares error: {round(100*np.mean((y_hat - y) ** 2) / (np.mean(y ** 2)), 2)}%' )\n",
    "    print(\"R2-score: %.2f\" % r2_score(y_hat, y) )\n",
    "    return [round(np.mean(np.absolute(y_hat - y)), 2), round(np.mean((y_hat - y) ** 2),2), \n",
    "            round(np.mean((y_hat - y) ** 2) / (np.mean(y ** 2)),2), \n",
    "            round(r2_score(y_hat, y),2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "6f249419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================\n",
      "Simple linear regression\n",
      "=====================\n",
      "Coefficients in simple linear regression:  [106.58]\n",
      "Intercept in simple linear regression:  19005.15\n",
      "Mean absolute error: 39865.08\n",
      "Residual sum of squares (MSE): 3435215272.80\n",
      "Normalized sum of squares error: 8.15%\n",
      "R2-score: -0.04\n",
      "Variance score: 0.55\n",
      "=====================\n",
      "Multi-linear regression with all features\n",
      "=====================\n",
      "First 20 coefficients in multilinear regression: [-11256.57, -13636.53, -9421.19, -27952.58, 7338.24, 8517.66, -3839.02, -7559.42, 14461.53, 12570.95, 17394.75, 7069.02, 2026.83, 6143.65, -1857.31, 1425.0, -94.88, -886.71, -6886.0, 4036.59]\n",
      "Intercept in multilinear regression: -620128.46\n",
      "Mean absolute error: 18439.88\n",
      "Residual sum of squares (MSE): 872213869.77\n",
      "Normalized sum of squares error: 2.07%\n",
      "R2-score: 0.85\n",
      "Variance score: 0.88\n",
      "=====================\n",
      "Multi-linear regression using 3 features most correlated with the SalePrice\n",
      "=====================\n",
      "Coefficients in multilinear regression:[53.74, 22981.98, 31857.67]\n",
      "Intercept in multilinear regression:  -148897.9\n",
      "Mean absolute error: 28640.00\n",
      "Residual sum of squares (MSE): 1892854037.10\n",
      "Normalized sum of squares error: 4.49%\n",
      "R2-score: 0.57\n"
     ]
    }
   ],
   "source": [
    "#Train-test split\n",
    "msk = np.random.rand(len(df)) < 0.8\n",
    "train = df[msk]\n",
    "test = df[~msk]\n",
    "\n",
    "metrics = {}\n",
    "\n",
    "#MODEL 1: Simple linear regression\n",
    "print('=====================')\n",
    "print('Simple linear regression')\n",
    "print('=====================')\n",
    "\n",
    "#a) Data preparation\n",
    "X_train = train['GrLivArea'].values.reshape(-1,1)\n",
    "y_train = train['SalePrice']\n",
    "X_test = test['GrLivArea'].values.reshape(-1,1)\n",
    "y_test = test['SalePrice']\n",
    "\n",
    "#b) Fitting the model\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X_train, y_train)\n",
    "print ('Coefficients in simple linear regression: ', [round(num,2) for num in regr.coef_])\n",
    "print ('Intercept in simple linear regression: ', round(regr.intercept_,2))\n",
    "\n",
    "#c) Drawing a graph\n",
    "# plt.scatter(train.GrLivArea, train.SalePrice,  color='blue')\n",
    "# plt.plot(train.GrLivArea, regr.coef_*train.GrLivArea + regr.intercept_, '-r')\n",
    "# plt.title('GrLivArea vs SalePrice')\n",
    "# plt.xlabel(\"GrLivArea\")\n",
    "# plt.ylabel(\"SalePrice\")\n",
    "\n",
    "#d) Prediction and evaluation\n",
    "y_test_hat = regr.predict(X_test)\n",
    "metrics['SLR'] = eval(y_test_hat, y_test )\n",
    "print('Variance score: %.2f' % regr.score(X_test, y_test))\n",
    "\n",
    "#MODEL 2: Multi-linear regression with all features\n",
    "print('=====================')\n",
    "print('Multi-linear regression with all features')\n",
    "print('=====================')\n",
    "#a) Data preparation\n",
    "X_train = train.drop(columns = ['SalePrice'])\n",
    "y_train = train['SalePrice']\n",
    "X_test = test.drop(columns = ['SalePrice'])\n",
    "y_test = test['SalePrice']\n",
    "\n",
    "#b) Fitting the model\n",
    "ml_regr = linear_model.LinearRegression()\n",
    "ml_regr.fit(X_train, y_train)\n",
    "print (f'First 20 coefficients in multilinear regression: {[round(num, 2) for num in ml_regr.coef_[:20]]}')\n",
    "print ('Intercept in multilinear regression: %.2f' % round(ml_regr.intercept_,2))\n",
    "\n",
    "#c) Drawing a graph - not clear how to do it in this case.\n",
    "\n",
    "#d) Prediction and evaluation\n",
    "y_test_hat = ml_regr.predict(X_test)\n",
    "metrics['MLR'] = eval(y_test_hat, y_test)\n",
    "print('Variance score: %.2f' % ml_regr.score(X_test, y_test))\n",
    "\n",
    "#MODEL 3: Multi-linear regression using 3 features most correlated with the SalePrice\n",
    "print('=====================')\n",
    "print('Multi-linear regression using 3 features most correlated with the SalePrice')\n",
    "print('=====================')\n",
    "#a) Data preparation\n",
    "X_train = train[['GrLivArea','OverallQual', 'ExterQual']]\n",
    "y_train = train['SalePrice']\n",
    "X_test = test[['GrLivArea','OverallQual', 'ExterQual']]\n",
    "y_test = test['SalePrice']\n",
    "\n",
    "#b) Fitting the model\n",
    "ml3_regr = linear_model.LinearRegression()\n",
    "ml3_regr.fit(X_train, y_train)\n",
    "print (f'Coefficients in multilinear regression:{[round(num, 2) for num in ml3_regr.coef_]}')\n",
    "print ('Intercept in multilinear regression: ', round(ml3_regr.intercept_,2))\n",
    "\n",
    "#c) Drawing a graph - not clear how to do it in this case.\n",
    "\n",
    "#d) Prediction and evaluation\n",
    "y_test_hat = ml3_regr.predict(X_test)\n",
    "metrics['MLR3'] = eval(y_test_hat, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "5ce7403a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================\n",
      "KNN regression with k = 1\n",
      "=====================\n",
      "Mean absolute error: 39501.98\n",
      "Residual sum of squares (MSE): 3672220449.47\n",
      "Normalized sum of squares error: 8.71%\n",
      "R2-score: 0.29\n",
      "=====================\n",
      "KNN regression with k = 2\n",
      "=====================\n",
      "Mean absolute error: 36329.46\n",
      "Residual sum of squares (MSE): 3466038146.86\n",
      "Normalized sum of squares error: 8.22%\n",
      "R2-score: 0.18\n",
      "=====================\n",
      "KNN regression with k = 3\n",
      "=====================\n",
      "Mean absolute error: 34247.41\n",
      "Residual sum of squares (MSE): 3093984920.79\n",
      "Normalized sum of squares error: 7.34%\n",
      "R2-score: 0.22\n",
      "=====================\n",
      "KNN regression with k = 4\n",
      "=====================\n",
      "Mean absolute error: 32990.50\n",
      "Residual sum of squares (MSE): 3017148726.88\n",
      "Normalized sum of squares error: 7.16%\n",
      "R2-score: 0.20\n",
      "=====================\n",
      "KNN regression with k = 5\n",
      "=====================\n",
      "Mean absolute error: 33426.02\n",
      "Residual sum of squares (MSE): 3142498243.32\n",
      "Normalized sum of squares error: 7.45%\n",
      "R2-score: 0.11\n",
      "=====================\n",
      "KNN regression with k = 6\n",
      "=====================\n",
      "Mean absolute error: 33340.68\n",
      "Residual sum of squares (MSE): 3147933120.29\n",
      "Normalized sum of squares error: 7.47%\n",
      "R2-score: 0.08\n",
      "=====================\n",
      "KNN regression with k = 7\n",
      "=====================\n",
      "Mean absolute error: 33547.89\n",
      "Residual sum of squares (MSE): 3231829144.76\n",
      "Normalized sum of squares error: 7.67%\n",
      "R2-score: 0.06\n",
      "=====================\n",
      "KNN regression with k = 8\n",
      "=====================\n",
      "Mean absolute error: 33393.22\n",
      "Residual sum of squares (MSE): 3119027583.80\n",
      "Normalized sum of squares error: 7.4%\n",
      "R2-score: 0.07\n",
      "=====================\n",
      "KNN regression with k = 9\n",
      "=====================\n",
      "Mean absolute error: 33725.06\n",
      "Residual sum of squares (MSE): 3151730823.86\n",
      "Normalized sum of squares error: 7.48%\n",
      "R2-score: 0.03\n"
     ]
    }
   ],
   "source": [
    "#MODEL 4: k nearest neighbors regression\n",
    "\n",
    "#a) Data preparation \n",
    "X_train = train.drop(columns = ['SalePrice'])\n",
    "y_train = train['SalePrice']\n",
    "X_test = test.drop(columns = ['SalePrice'])\n",
    "y_test = test['SalePrice']\n",
    "\n",
    "#d) Prediction and evaluation\n",
    "for x in range(1, 10):\n",
    "    y_test_hat = KNeighborsRegressor(x).fit(X_train,y_train).predict(X_test)\n",
    "    print('=====================')\n",
    "    print(f'KNN regression with k = {x}')\n",
    "    print('=====================')\n",
    "    metrics[f'KNN_{x}']= eval(y_test_hat, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "783fd8bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\barto\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================\n",
      "Support vector regression with epsilon = 25000\n",
      "=====================\n",
      "Mean absolute error: 25484.13\n",
      "Residual sum of squares (MSE): 1513433299.46\n",
      "Normalized sum of squares error: 3.59%\n",
      "R2-score: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\barto\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================\n",
      "Support vector regression with epsilon = 50000\n",
      "=====================\n",
      "Mean absolute error: 25945.70\n",
      "Residual sum of squares (MSE): 1437666768.69\n",
      "Normalized sum of squares error: 3.41%\n",
      "R2-score: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\barto\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================\n",
      "Support vector regression with epsilon = 75000\n",
      "=====================\n",
      "Mean absolute error: 28446.65\n",
      "Residual sum of squares (MSE): 1620942895.99\n",
      "Normalized sum of squares error: 3.85%\n",
      "R2-score: 0.73\n",
      "=====================\n",
      "Support vector regression with epsilon = 100000\n",
      "=====================\n",
      "Mean absolute error: 31974.25\n",
      "Residual sum of squares (MSE): 2008554010.33\n",
      "Normalized sum of squares error: 4.76%\n",
      "R2-score: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\barto\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#MODEL 5: SVM regression\n",
    "\n",
    "#a) Data preparation \n",
    "X_train = train.drop(columns = ['SalePrice'])\n",
    "y_train = train['SalePrice']\n",
    "X_test = test.drop(columns = ['SalePrice'])\n",
    "y_test = test['SalePrice']\n",
    "\n",
    "#d) Prediction and evaluation\n",
    "for x in range(1,5):\n",
    "    y_test_hat = LinearSVR(C=1, epsilon=25000*x, max_iter=100000).fit(X_train,y_train).predict(X_test)\n",
    "    print('=====================')\n",
    "    print(f'Support vector regression with epsilon = {25000*x}')\n",
    "    print('=====================')\n",
    "    metrics[f'SVM_epsilon={25000*x}'] = eval(y_test_hat, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "282cf21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================\n",
      "Decision tree with max_depth = 1\n",
      "=====================\n",
      "Mean absolute error: 44522.43\n",
      "Residual sum of squares (MSE): 4279754209.15\n",
      "Normalized sum of squares error: 10.15%\n",
      "R2-score: -0.49\n",
      "=====================\n",
      "Decision tree with max_depth = 2\n",
      "=====================\n",
      "Mean absolute error: 36167.78\n",
      "Residual sum of squares (MSE): 2958737522.00\n",
      "Normalized sum of squares error: 7.02%\n",
      "R2-score: 0.21\n",
      "=====================\n",
      "Decision tree with max_depth = 3\n",
      "=====================\n",
      "Mean absolute error: 32151.01\n",
      "Residual sum of squares (MSE): 2259665027.34\n",
      "Normalized sum of squares error: 5.36%\n",
      "R2-score: 0.46\n",
      "=====================\n",
      "Decision tree with max_depth = 4\n",
      "=====================\n",
      "Mean absolute error: 29222.93\n",
      "Residual sum of squares (MSE): 1967003972.08\n",
      "Normalized sum of squares error: 4.67%\n",
      "R2-score: 0.57\n",
      "=====================\n",
      "Decision tree with max_depth = 5\n",
      "=====================\n",
      "Mean absolute error: 26945.08\n",
      "Residual sum of squares (MSE): 1701538392.00\n",
      "Normalized sum of squares error: 4.04%\n",
      "R2-score: 0.69\n",
      "=====================\n",
      "Decision tree with max_depth = 6\n",
      "=====================\n",
      "Mean absolute error: 25305.99\n",
      "Residual sum of squares (MSE): 1477304941.02\n",
      "Normalized sum of squares error: 3.5%\n",
      "R2-score: 0.75\n",
      "=====================\n",
      "Decision tree with max_depth = 7\n",
      "=====================\n",
      "Mean absolute error: 24455.06\n",
      "Residual sum of squares (MSE): 1299564534.30\n",
      "Normalized sum of squares error: 3.08%\n",
      "R2-score: 0.79\n",
      "=====================\n",
      "Decision tree with max_depth = 8\n",
      "=====================\n",
      "Mean absolute error: 25921.87\n",
      "Residual sum of squares (MSE): 1661881481.99\n",
      "Normalized sum of squares error: 3.94%\n",
      "R2-score: 0.72\n",
      "=====================\n",
      "Decision tree with max_depth = 9\n",
      "=====================\n",
      "Mean absolute error: 25356.75\n",
      "Residual sum of squares (MSE): 1465440149.34\n",
      "Normalized sum of squares error: 3.48%\n",
      "R2-score: 0.78\n"
     ]
    }
   ],
   "source": [
    "#MODEL 6: Decision tree\n",
    "\n",
    "#a) Data preparation \n",
    "X_train = train.drop(columns = ['SalePrice'])\n",
    "y_train = train['SalePrice']\n",
    "X_test = test.drop(columns = ['SalePrice'])\n",
    "y_test = test['SalePrice']\n",
    "\n",
    "#d) Prediction and evaluation\n",
    "for x in range(1,10):\n",
    "    y_test_hat = DecisionTreeRegressor(max_depth = x).fit(X_train,y_train).predict(X_test)\n",
    "    print('=====================')\n",
    "    print(f'Decision tree with max_depth = {x}')\n",
    "    print('=====================')\n",
    "    metrics[f'Decision_tree_max_depth={x}'] = eval(y_test_hat, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "63150975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>relative MSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SLR</th>\n",
       "      <td>39865.08</td>\n",
       "      <td>3435215272.80</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLR</th>\n",
       "      <td>18439.88</td>\n",
       "      <td>872213869.77</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLR3</th>\n",
       "      <td>28640.00</td>\n",
       "      <td>1892854037.10</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN_1</th>\n",
       "      <td>39501.98</td>\n",
       "      <td>3672220449.47</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN_2</th>\n",
       "      <td>36329.46</td>\n",
       "      <td>3466038146.86</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN_3</th>\n",
       "      <td>34247.41</td>\n",
       "      <td>3093984920.79</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN_4</th>\n",
       "      <td>32990.50</td>\n",
       "      <td>3017148726.88</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN_5</th>\n",
       "      <td>33426.02</td>\n",
       "      <td>3142498243.32</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN_6</th>\n",
       "      <td>33340.68</td>\n",
       "      <td>3147933120.29</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN_7</th>\n",
       "      <td>33547.89</td>\n",
       "      <td>3231829144.76</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN_8</th>\n",
       "      <td>33393.22</td>\n",
       "      <td>3119027583.80</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN_9</th>\n",
       "      <td>33725.06</td>\n",
       "      <td>3151730823.86</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM_epsilon=25000</th>\n",
       "      <td>25484.13</td>\n",
       "      <td>1513433299.46</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM_epsilon=50000</th>\n",
       "      <td>25945.70</td>\n",
       "      <td>1437666768.69</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM_epsilon=75000</th>\n",
       "      <td>28446.65</td>\n",
       "      <td>1620942895.99</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM_epsilon=100000</th>\n",
       "      <td>31974.25</td>\n",
       "      <td>2008554010.33</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision_tree_max_depth=1</th>\n",
       "      <td>44522.43</td>\n",
       "      <td>4279754209.15</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision_tree_max_depth=2</th>\n",
       "      <td>36167.78</td>\n",
       "      <td>2958737522.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision_tree_max_depth=3</th>\n",
       "      <td>32151.01</td>\n",
       "      <td>2259665027.34</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision_tree_max_depth=4</th>\n",
       "      <td>29222.93</td>\n",
       "      <td>1967003972.08</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision_tree_max_depth=5</th>\n",
       "      <td>26945.08</td>\n",
       "      <td>1701538392.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision_tree_max_depth=6</th>\n",
       "      <td>25305.99</td>\n",
       "      <td>1477304941.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision_tree_max_depth=7</th>\n",
       "      <td>24455.06</td>\n",
       "      <td>1299564534.30</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision_tree_max_depth=8</th>\n",
       "      <td>25921.87</td>\n",
       "      <td>1661881481.99</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision_tree_max_depth=9</th>\n",
       "      <td>25356.75</td>\n",
       "      <td>1465440149.34</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               MAE           MSE  relative MSE    R2\n",
       "SLR                       39865.08 3435215272.80          0.08 -0.04\n",
       "MLR                       18439.88  872213869.77          0.02  0.85\n",
       "MLR3                      28640.00 1892854037.10          0.04  0.57\n",
       "KNN_1                     39501.98 3672220449.47          0.09  0.29\n",
       "KNN_2                     36329.46 3466038146.86          0.08  0.18\n",
       "KNN_3                     34247.41 3093984920.79          0.07  0.22\n",
       "KNN_4                     32990.50 3017148726.88          0.07  0.20\n",
       "KNN_5                     33426.02 3142498243.32          0.07  0.11\n",
       "KNN_6                     33340.68 3147933120.29          0.07  0.08\n",
       "KNN_7                     33547.89 3231829144.76          0.08  0.06\n",
       "KNN_8                     33393.22 3119027583.80          0.07  0.07\n",
       "KNN_9                     33725.06 3151730823.86          0.07  0.03\n",
       "SVM_epsilon=25000         25484.13 1513433299.46          0.04  0.67\n",
       "SVM_epsilon=50000         25945.70 1437666768.69          0.03  0.73\n",
       "SVM_epsilon=75000         28446.65 1620942895.99          0.04  0.73\n",
       "SVM_epsilon=100000        31974.25 2008554010.33          0.05  0.55\n",
       "Decision_tree_max_depth=1 44522.43 4279754209.15          0.10 -0.49\n",
       "Decision_tree_max_depth=2 36167.78 2958737522.00          0.07  0.21\n",
       "Decision_tree_max_depth=3 32151.01 2259665027.34          0.05  0.46\n",
       "Decision_tree_max_depth=4 29222.93 1967003972.08          0.05  0.57\n",
       "Decision_tree_max_depth=5 26945.08 1701538392.00          0.04  0.69\n",
       "Decision_tree_max_depth=6 25305.99 1477304941.02          0.04  0.75\n",
       "Decision_tree_max_depth=7 24455.06 1299564534.30          0.03  0.79\n",
       "Decision_tree_max_depth=8 25921.87 1661881481.99          0.04  0.72\n",
       "Decision_tree_max_depth=9 25356.75 1465440149.34          0.03  0.78"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "df = pd.DataFrame.from_dict(metrics, orient='index', dtype=float, columns= ['MAE', 'MSE','relative MSE', 'R2'])\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
